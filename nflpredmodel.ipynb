{
   "cell_type": "markdown",
   "id": "0c7e5126",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Dependencies\n",
    "\n",
    "Installing the required packages:\n",
    "- **xgboost**: Advanced gradient boosting machine learning library\n",
    "- **nfl_data_py**: Official NFL data package for accessing play-by-play, team stats, and schedule data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1f3179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: xgboost in c:\\users\\sking\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: nfl_data_py in c:\\users\\sking\\anaconda3\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\sking\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sking\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\sking\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: pandas<2.0,>=1.0 in c:\\users\\sking\\anaconda3\\lib\\site-packages (from nfl_data_py) (1.5.3)\n",
      "Requirement already satisfied: appdirs>1 in c:\\users\\sking\\anaconda3\\lib\\site-packages (from nfl_data_py) (1.4.4)\n",
      "Requirement already satisfied: fastparquet>0.5 in c:\\users\\sking\\anaconda3\\lib\\site-packages (from nfl_data_py) (2024.11.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\sking\\anaconda3\\lib\\site-packages (from fastparquet>0.5->nfl_data_py) (2.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sking\\anaconda3\\lib\\site-packages (from fastparquet>0.5->nfl_data_py) (2024.6.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sking\\anaconda3\\lib\\site-packages (from fastparquet>0.5->nfl_data_py) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sking\\anaconda3\\lib\\site-packages (from pandas<2.0,>=1.0->nfl_data_py) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sking\\anaconda3\\lib\\site-packages (from pandas<2.0,>=1.0->nfl_data_py) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sking\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<2.0,>=1.0->nfl_data_py) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost nfl_data_py pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8df4b",
   "metadata": {},
   "source": [
    "## Step 2: NFLGamePredictor Class & Data Collection\n",
    "\n",
    "This cell defines the main `NFLGamePredictor` class that handles:\n",
    "\n",
    "**Data Collection:**\n",
    "- Downloads 10+ years of NFL data (2015-2025)\n",
    "- Collects play-by-play data, team statistics, and game schedules\n",
    "- Processes team performance metrics (passing/rushing yards, points, turnovers)\n",
    "\n",
    "**Feature Engineering:**\n",
    "- Creates team-level features from raw game data\n",
    "- Calculates advantages between home/away teams\n",
    "- Includes contextual factors like home field advantage\n",
    "\n",
    "**Model Training:**\n",
    "- Tests multiple algorithms (Random Forest, XGBoost, Logistic Regression)\n",
    "- Uses feature selection to identify most predictive statistics\n",
    "- Creates ensemble model combining best performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2522d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This may take a few minutes to download NFL data...\n",
      "Collecting NFL data from 2015 to 2025...\n",
      "Downloading play-by-play data...\n",
      "2015 done.\n",
      "2016 done.\n",
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "2023 done.\n",
      "2024 done.\n",
      "2025 done.\n",
      "Downcasting floats.\n",
      "✓ Play-by-play data downloaded successfully\n",
      "Downloading team information...\n",
      "Downloading weekly team data...\n",
      "Error downloading weekly data: HTTP Error 404: Not Found\n",
      "Trying with 2015-2024 data only...\n",
      "Downcasting floats.\n",
      "✓ Weekly data downloaded (2015-2024)\n",
      "Downloading schedule data...\n",
      "✓ Schedule data downloaded successfully\n",
      "Attempting to download 2025 Week 1 data...\n",
      "2025 done.\n",
      "Downcasting floats.\n",
      "✓ 2025 play-by-play data added\n",
      "2025 data not available yet: HTTP Error 404: Not Found\n",
      "Proceeding with 2015-2024 data only\n",
      "Collected 515627 play-by-play records\n",
      "Collected 54479 weekly team records\n",
      "Collected 3015 scheduled games\n",
      "\n",
      "Saving data to CSV files in 'nfl_data' folder...\n",
      "✓ Saved play-by-play data: nfl_data\\pbp_data_2015_2025.csv (515,627 rows)\n",
      "✓ Saved weekly data: nfl_data\\weekly_data_2015_2025.csv (54,479 rows)\n",
      "✓ Saved schedule data: nfl_data\\schedule_data_2015_2025.csv (3,015 rows)\n",
      "✓ Saved team info: nfl_data\\team_info.csv (36 rows)\n",
      "\n",
      "Saving sample data for quick inspection...\n",
      "✓ Saved PBP sample: nfl_data\\pbp_sample.csv (1,000 rows)\n",
      "✓ Saved weekly sample: nfl_data\\weekly_sample.csv (5,597 rows from 2024-2025)\n",
      "\n",
      "DATA STRUCTURE OVERVIEW:\n",
      "==================================================\n",
      "Play-by-Play Columns (398): ['play_id', 'game_id', 'old_game_id', 'home_team', 'away_team', 'season_type', 'week', 'posteam', 'posteam_type', 'defteam']...\n",
      "Weekly Data Columns (53): ['player_id', 'player_name', 'player_display_name', 'position', 'position_group', 'headshot_url', 'recent_team', 'season', 'week', 'season_type', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'interceptions', 'sacks', 'sack_yards', 'sack_fumbles', 'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch', 'passing_first_downs', 'passing_epa', 'passing_2pt_conversions', 'pacr', 'dakota', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_fumbles', 'receiving_fumbles_lost', 'receiving_air_yards', 'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa', 'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share', 'wopr', 'special_teams_tds', 'fantasy_points', 'fantasy_points_ppr']\n",
      "Schedule Columns (46): ['game_id', 'season', 'game_type', 'week', 'gameday', 'weekday', 'gametime', 'away_team', 'away_score', 'home_team', 'home_score', 'location', 'result', 'total', 'overtime', 'old_game_id', 'gsis', 'nfl_detail_id', 'pfr', 'pff', 'espn', 'ftn', 'away_rest', 'home_rest', 'away_moneyline', 'home_moneyline', 'spread_line', 'away_spread_odds', 'home_spread_odds', 'total_line', 'under_odds', 'over_odds', 'div_game', 'roof', 'surface', 'temp', 'wind', 'away_qb_id', 'home_qb_id', 'away_qb_name', 'home_qb_name', 'away_coach', 'home_coach', 'referee', 'stadium_id', 'stadium']\n",
      "Team Info Columns (16): ['team_abbr', 'team_name', 'team_id', 'team_nick', 'team_conf', 'team_division', 'team_color', 'team_color2', 'team_color3', 'team_color4', 'team_logo_wikipedia', 'team_logo_espn', 'team_wordmark', 'team_conference_logo', 'team_league_logo', 'team_logo_squared']\n",
      "\n",
      "DATA SAVED SUCCESSFULLY!\n",
      "Check the 'nfl_data' folder to examine the downloaded data.\n",
      "Building dataset from collected data...\n",
      "Created dataset with 2465 games\n",
      "✓ Saved processed game features: nfl_data\\processed_game_features.csv (2,465 rows)\n",
      "\n",
      "PROCESSED FEATURES (28 columns):\n",
      "==================================================\n",
      "  - home_passing_ypg\n",
      "  - home_rushing_ypg\n",
      "  - home_total_ypg\n",
      "  - home_points_pg\n",
      "  - home_passing_tds_pg\n",
      "  - home_turnovers_pg\n",
      "  - home_injury_pct\n",
      "  - away_passing_ypg\n",
      "  - away_rushing_ypg\n",
      "  - away_total_ypg\n",
      "  - away_points_pg\n",
      "  - away_passing_tds_pg\n",
      "  - away_turnovers_pg\n",
      "  - away_injury_pct\n",
      "  - passing_advantage\n",
      "  - rushing_advantage\n",
      "  - scoring_advantage\n",
      "  - turnover_advantage\n",
      "  - injury_advantage\n",
      "  - home_field_advantage\n",
      "  - is_playoff\n",
      "  - is_neutral\n",
      "  - week\n",
      "  - season\n",
      "  - home_win\n",
      "  - home_score\n",
      "  - away_score\n",
      "  - game_id\n",
      "Starting feature selection with 19 features...\n",
      "2 features: 0.522 (+/- 0.019)\n",
      "3 features: 0.532 (+/- 0.021)\n",
      "4 features: 0.516 (+/- 0.016)\n",
      "5 features: 0.525 (+/- 0.024)\n",
      "6 features: 0.524 (+/- 0.029)\n",
      "7 features: 0.519 (+/- 0.021)\n",
      "8 features: 0.530 (+/- 0.025)\n",
      "9 features: 0.536 (+/- 0.013)\n",
      "10 features: 0.541 (+/- 0.012)\n",
      "11 features: 0.528 (+/- 0.016)\n",
      "12 features: 0.539 (+/- 0.030)\n",
      "13 features: 0.539 (+/- 0.022)\n",
      "Best number of features: 10\n",
      "Selected features:\n",
      "  - home_passing_ypg\n",
      "  - home_points_pg\n",
      "  - home_passing_tds_pg\n",
      "  - home_turnovers_pg\n",
      "  - away_passing_tds_pg\n",
      "  - away_turnovers_pg\n",
      "  - scoring_advantage\n",
      "  - turnover_advantage\n",
      "  - is_playoff\n",
      "  - season\n",
      "\n",
      "Training and evaluating models...\n",
      "Logistic Regression: 0.596 (+/- 0.019)\n",
      "Decision Tree: 0.557 (+/- 0.017)\n",
      "Random Forest: 0.592 (+/- 0.016)\n",
      "XGBoost: 0.583 (+/- 0.015)\n",
      "Training ensemble model...\n",
      "\n",
      "2023 season prediction accuracy: 0.580\n",
      "High confidence bet accuracy: 0.554 (65 games)\n",
      "\n",
      "Predictor trained successfully!\n",
      "You can now use predictor.predict_games() on new data.\n"
     ]
    }
   ],
   "source": [
    "# NFL Game Prediction using nfl_data_py\n",
    "# Updated version of NFL prediction pipeline using modern, maintained data source\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot  \n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV as CCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Advanced ML libraries\n",
    "try: \n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "# NFL data library\n",
    "try:\n",
    "    import nfl_data_py as nfl\n",
    "    HAS_NFL_DATA = True\n",
    "except ImportError:\n",
    "    HAS_NFL_DATA = False\n",
    "    print(\"nfl_data_py not available. Install with: pip install nfl_data_py\")\n",
    "\n",
    "class NFLGamePredictor:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.best_features = []\n",
    "        self.scaler = StandardScaler()\n",
    "        self.final_model = None\n",
    "        \n",
    "    def collect_data(self, start_year=2010, end_year=2024, save_csv=True, data_folder='nfl_data'):\n",
    "        \"\"\"Collect comprehensive NFL data using nfl_data_py and save as CSV files\"\"\"\n",
    "        \n",
    "        if not HAS_NFL_DATA:\n",
    "            raise ImportError(\"nfl_data_py is required. Install with: pip install nfl_data_py\")\n",
    "        \n",
    "        print(f\"Collecting NFL data from {start_year} to {end_year}...\")\n",
    "        \n",
    "        # Create data folder if it doesn't exist\n",
    "        if save_csv and not os.path.exists(data_folder):\n",
    "            os.makedirs(data_folder)\n",
    "            print(f\"Created data folder: {data_folder}\")\n",
    "        \n",
    "        years = list(range(start_year, end_year + 1))\n",
    "        \n",
    "        # Get play-by-play data for game-level statistics\n",
    "        print(\"Downloading play-by-play data...\")\n",
    "        try:\n",
    "            pbp_data = nfl.import_pbp_data(years)\n",
    "            print(f\"✓ Play-by-play data downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading play-by-play data: {e}\")\n",
    "            # Try with reduced year range\n",
    "            years = list(range(start_year, 2024 + 1))\n",
    "            pbp_data = nfl.import_pbp_data(years)\n",
    "            print(f\"✓ Play-by-play data downloaded (adjusted to {start_year}-2024)\")\n",
    "        \n",
    "        # Get team information\n",
    "        print(\"Downloading team information...\")\n",
    "        teams = nfl.import_team_desc()\n",
    "        team_dict = teams.set_index('team_abbr')['team_name'].to_dict()\n",
    "        \n",
    "        # Get weekly data for season-long team statistics\n",
    "        print(\"Downloading weekly team data...\")\n",
    "        try:\n",
    "            weekly_data = nfl.import_weekly_data(years)\n",
    "            print(f\"✓ Weekly data downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading weekly data: {e}\")\n",
    "            print(\"Trying with 2015-2024 data only...\")\n",
    "            # Fall back to confirmed available years\n",
    "            years_safe = list(range(2015, 2024 + 1))\n",
    "            weekly_data = nfl.import_weekly_data(years_safe)\n",
    "            print(f\"✓ Weekly data downloaded (2015-2024)\")\n",
    "        \n",
    "        # Get schedule data\n",
    "        print(\"Downloading schedule data...\")\n",
    "        try:\n",
    "            schedule_data = nfl.import_schedules(years)\n",
    "            print(f\"✓ Schedule data downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading schedule data: {e}\")\n",
    "            print(\"Trying with 2015-2024 data only...\")\n",
    "            # Fall back to confirmed available years\n",
    "            years_safe = list(range(2015, 2024 + 1))\n",
    "            schedule_data = nfl.import_schedules(years_safe)\n",
    "            print(f\"✓ Schedule data downloaded (2015-2024)\")\n",
    "        \n",
    "        # Try to get 2025 Week 1 data separately if available\n",
    "        print(\"Attempting to download 2025 Week 1 data...\")\n",
    "        try:\n",
    "            pbp_2025 = nfl.import_pbp_data([2025])\n",
    "            if not pbp_2025.empty:\n",
    "                pbp_data = pd.concat([pbp_data, pbp_2025], ignore_index=True)\n",
    "                print(\"✓ 2025 play-by-play data added\")\n",
    "            \n",
    "            weekly_2025 = nfl.import_weekly_data([2025])\n",
    "            if not weekly_2025.empty:\n",
    "                weekly_data = pd.concat([weekly_data, weekly_2025], ignore_index=True)\n",
    "                print(\"✓ 2025 weekly data added\")\n",
    "                \n",
    "            schedule_2025 = nfl.import_schedules([2025])\n",
    "            if not schedule_2025.empty:\n",
    "                schedule_data = pd.concat([schedule_data, schedule_2025], ignore_index=True)\n",
    "                print(\"✓ 2025 schedule data added\")\n",
    "        except Exception as e:\n",
    "            print(f\"2025 data not available yet: {e}\")\n",
    "            print(\"Proceeding with 2015-2024 data only\")\n",
    "        \n",
    "        print(f\"Collected {len(pbp_data)} play-by-play records\")\n",
    "        print(f\"Collected {len(weekly_data)} weekly team records\") \n",
    "        print(f\"Collected {len(schedule_data)} scheduled games\")\n",
    "        \n",
    "        # Save data as CSV files if requested\n",
    "        if save_csv:\n",
    "            print(f\"\\nSaving data to CSV files in '{data_folder}' folder...\")\n",
    "            \n",
    "            # Save play-by-play data (this will be large)\n",
    "            pbp_file = os.path.join(data_folder, f'pbp_data_{start_year}_{end_year}.csv')\n",
    "            pbp_data.to_csv(pbp_file, index=False)\n",
    "            print(f\"✓ Saved play-by-play data: {pbp_file} ({len(pbp_data):,} rows)\")\n",
    "            \n",
    "            # Save weekly data\n",
    "            weekly_file = os.path.join(data_folder, f'weekly_data_{start_year}_{end_year}.csv')\n",
    "            weekly_data.to_csv(weekly_file, index=False)\n",
    "            print(f\"✓ Saved weekly data: {weekly_file} ({len(weekly_data):,} rows)\")\n",
    "            \n",
    "            # Save schedule data\n",
    "            schedule_file = os.path.join(data_folder, f'schedule_data_{start_year}_{end_year}.csv')\n",
    "            schedule_data.to_csv(schedule_file, index=False)\n",
    "            print(f\"✓ Saved schedule data: {schedule_file} ({len(schedule_data):,} rows)\")\n",
    "            \n",
    "            # Save team information\n",
    "            teams_file = os.path.join(data_folder, 'team_info.csv')\n",
    "            teams.to_csv(teams_file, index=False)\n",
    "            print(f\"✓ Saved team info: {teams_file} ({len(teams):,} rows)\")\n",
    "            \n",
    "            # Save a sample of each dataset for quick inspection\n",
    "            print(f\"\\nSaving sample data for quick inspection...\")\n",
    "            \n",
    "            # Sample play-by-play (first 1000 rows)\n",
    "            pbp_sample_file = os.path.join(data_folder, 'pbp_sample.csv')\n",
    "            pbp_data.head(1000).to_csv(pbp_sample_file, index=False)\n",
    "            print(f\"✓ Saved PBP sample: {pbp_sample_file} (1,000 rows)\")\n",
    "            \n",
    "            # Sample weekly data (recent season)\n",
    "            weekly_sample = weekly_data[weekly_data['season'] >= end_year - 1]\n",
    "            weekly_sample_file = os.path.join(data_folder, 'weekly_sample.csv')\n",
    "            weekly_sample.to_csv(weekly_sample_file, index=False)\n",
    "            print(f\"✓ Saved weekly sample: {weekly_sample_file} ({len(weekly_sample):,} rows from {end_year-1}-{end_year})\")\n",
    "            \n",
    "            # Show column information\n",
    "            print(f\"\\nDATA STRUCTURE OVERVIEW:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Play-by-Play Columns ({len(pbp_data.columns)}): {list(pbp_data.columns[:10])}...\")\n",
    "            print(f\"Weekly Data Columns ({len(weekly_data.columns)}): {list(weekly_data.columns)}\")\n",
    "            print(f\"Schedule Columns ({len(schedule_data.columns)}): {list(schedule_data.columns)}\")\n",
    "            print(f\"Team Info Columns ({len(teams.columns)}): {list(teams.columns)}\")\n",
    "            \n",
    "            print(f\"\\nDATA SAVED SUCCESSFULLY!\")\n",
    "            print(f\"Check the '{data_folder}' folder to examine the downloaded data.\")\n",
    "        \n",
    "        return pbp_data, weekly_data, schedule_data, team_dict\n",
    "    \n",
    "    def _calculate_injury_percentage(self, team_data):\n",
    "        \"\"\"\n",
    "        Calculate estimated injury percentage based on available performance metrics\n",
    "        \n",
    "        This method estimates team injury impact by analyzing performance consistency\n",
    "        and key player availability indicators in the data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # If we have specific injury data columns, use them\n",
    "        if 'injuries' in team_data.columns:\n",
    "            return team_data['injuries'].mean()\n",
    "        \n",
    "        # Estimate injury impact based on performance variance and available metrics\n",
    "        # Higher variance in key stats might indicate injury-related inconsistency\n",
    "        \n",
    "        injury_indicators = []\n",
    "        \n",
    "        # 1. Passing performance consistency (QB health indicator)\n",
    "        if 'passing_yards' in team_data.columns and len(team_data) > 1:\n",
    "            passing_std = team_data['passing_yards'].std()\n",
    "            passing_mean = team_data['passing_yards'].mean()\n",
    "            if passing_mean > 0:\n",
    "                passing_variance = (passing_std / passing_mean) * 100\n",
    "                injury_indicators.append(min(passing_variance, 30))  # Cap at 30%\n",
    "        \n",
    "        # 2. Rushing performance consistency (RB/OL health indicator)\n",
    "        if 'rushing_yards' in team_data.columns and len(team_data) > 1:\n",
    "            rushing_std = team_data['rushing_yards'].std()\n",
    "            rushing_mean = team_data['rushing_yards'].mean()\n",
    "            if rushing_mean > 0:\n",
    "                rushing_variance = (rushing_std / rushing_mean) * 100\n",
    "                injury_indicators.append(min(rushing_variance, 25))  # Cap at 25%\n",
    "        \n",
    "        # 3. Completion percentage consistency (QB/WR health indicator)\n",
    "        if 'completions' in team_data.columns and 'passing_attempts' in team_data.columns:\n",
    "            comp_pct = team_data['completions'] / (team_data['passing_attempts'] + 0.1)  # Avoid division by zero\n",
    "            if len(comp_pct) > 1:\n",
    "                comp_std = comp_pct.std()\n",
    "                comp_variance = comp_std * 100\n",
    "                injury_indicators.append(min(comp_variance, 20))  # Cap at 20%\n",
    "        \n",
    "        # 4. Fantasy points consistency (overall team health)\n",
    "        if 'fantasy_points' in team_data.columns and len(team_data) > 1:\n",
    "            fp_std = team_data['fantasy_points'].std()\n",
    "            fp_mean = team_data['fantasy_points'].mean()\n",
    "            if fp_mean > 0:\n",
    "                fp_variance = (fp_std / fp_mean) * 100\n",
    "                injury_indicators.append(min(fp_variance, 35))  # Cap at 35%\n",
    "        \n",
    "        # Calculate weighted average injury percentage\n",
    "        if injury_indicators:\n",
    "            # Weight more recent games higher (if we have game order info)\n",
    "            weights = [1.0] * len(injury_indicators)  \n",
    "            weighted_avg = sum(i * w for i, w in zip(injury_indicators, weights)) / sum(weights)\n",
    "            \n",
    "            # Normalize to 0-100% range and apply league baseline\n",
    "            # NFL teams typically have 10-25% of roster dealing with some injury\n",
    "            baseline_injury_rate = 15.0  # League average baseline\n",
    "            estimated_injury_pct = min(max(weighted_avg, 5.0), 40.0)  # 5-40% range\n",
    "            \n",
    "            # Blend with baseline for more realistic estimates\n",
    "            final_injury_pct = (estimated_injury_pct * 0.7) + (baseline_injury_rate * 0.3)\n",
    "            \n",
    "            return final_injury_pct\n",
    "        \n",
    "        # Default injury rate if no data available\n",
    "        return 15.0  # NFL league average\n",
    "    \n",
    "    def create_team_features(self, weekly_data, season, week):\n",
    "        \"\"\"Create team-level features for a specific season/week\"\"\"\n",
    "        \n",
    "        # Filter data up to the current week\n",
    "        season_data = weekly_data[\n",
    "            (weekly_data['season'] == season) & \n",
    "            (weekly_data['week'] < week)\n",
    "        ]\n",
    "        \n",
    "        if season_data.empty:\n",
    "            return {}\n",
    "        \n",
    "        # Calculate season averages for each team\n",
    "        team_features = {}\n",
    "        \n",
    "        for team in season_data['recent_team'].unique():\n",
    "            team_data = season_data[season_data['recent_team'] == team]\n",
    "            \n",
    "            if len(team_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Offensive features\n",
    "            features = {\n",
    "                'passing_yards_pg': team_data['passing_yards'].mean(),\n",
    "                'rushing_yards_pg': team_data['rushing_yards'].mean(), \n",
    "                'total_yards_pg': team_data['passing_yards'].mean() + team_data['rushing_yards'].mean(),\n",
    "                'points_pg': team_data['fantasy_points'].mean() if 'fantasy_points' in team_data.columns else 0,\n",
    "                'completions_pg': team_data['completions'].mean(),\n",
    "                'passing_tds_pg': team_data['passing_tds'].mean(),\n",
    "                'interceptions_thrown_pg': team_data['interceptions'].mean(),\n",
    "                'rushing_tds_pg': team_data['rushing_tds'].mean(),\n",
    "                'fumbles_lost_pg': team_data['fumbles_lost'].mean() if 'fumbles_lost' in team_data.columns else 0,\n",
    "                \n",
    "                # Defensive features (opponent stats)\n",
    "                'opp_passing_yards_pg': 0,  # Will be calculated separately\n",
    "                'opp_rushing_yards_pg': 0,\n",
    "                'opp_points_pg': 0,\n",
    "                \n",
    "                # Team health and availability metrics\n",
    "                'injury_percentage': self._calculate_injury_percentage(team_data),\n",
    "                \n",
    "                # Advanced metrics\n",
    "                'turnover_ratio': (team_data['interceptions'].mean() - \n",
    "                                 team_data['interceptions'].mean()),  # Simplified\n",
    "                'games_played': len(team_data)\n",
    "            }\n",
    "            \n",
    "            team_features[team] = features\n",
    "        \n",
    "        return team_features\n",
    "    \n",
    "    def create_game_features(self, home_team, away_team, team_features, \n",
    "                           season, week, is_playoff=False, is_neutral=False):\n",
    "        \"\"\"Create features for a specific matchup\"\"\"\n",
    "        \n",
    "        if home_team not in team_features or away_team not in team_features:\n",
    "            return None\n",
    "        \n",
    "        home_stats = team_features[home_team]\n",
    "        away_stats = team_features[away_team]\n",
    "        \n",
    "        # Create matchup features\n",
    "        features = {\n",
    "            # Home team offensive stats\n",
    "            'home_passing_ypg': home_stats['passing_yards_pg'],\n",
    "            'home_rushing_ypg': home_stats['rushing_yards_pg'],\n",
    "            'home_total_ypg': home_stats['total_yards_pg'],\n",
    "            'home_points_pg': home_stats['points_pg'],\n",
    "            'home_passing_tds_pg': home_stats['passing_tds_pg'],\n",
    "            'home_turnovers_pg': home_stats.get('fumbles_lost_pg', 0) + home_stats['interceptions_thrown_pg'],\n",
    "            'home_injury_pct': home_stats['injury_percentage'],\n",
    "            \n",
    "            # Away team offensive stats  \n",
    "            'away_passing_ypg': away_stats['passing_yards_pg'],\n",
    "            'away_rushing_ypg': away_stats['rushing_yards_pg'],\n",
    "            'away_total_ypg': away_stats['total_yards_pg'],\n",
    "            'away_points_pg': away_stats['points_pg'],\n",
    "            'away_passing_tds_pg': away_stats['passing_tds_pg'],\n",
    "            'away_turnovers_pg': away_stats.get('fumbles_lost_pg', 0) + away_stats['interceptions_thrown_pg'],\n",
    "            'away_injury_pct': away_stats['injury_percentage'],\n",
    "            \n",
    "            # Matchup advantages\n",
    "            'passing_advantage': home_stats['passing_yards_pg'] - away_stats['passing_yards_pg'],\n",
    "            'rushing_advantage': home_stats['rushing_yards_pg'] - away_stats['rushing_yards_pg'],\n",
    "            'scoring_advantage': home_stats['points_pg'] - away_stats['points_pg'],\n",
    "            'turnover_advantage': away_stats.get('fumbles_lost_pg', 0) + away_stats['interceptions_thrown_pg'] - \n",
    "                                (home_stats.get('fumbles_lost_pg', 0) + home_stats['interceptions_thrown_pg']),\n",
    "            'injury_advantage': away_stats['injury_percentage'] - home_stats['injury_percentage'],  # Lower injury % is better\n",
    "            \n",
    "            # Game context\n",
    "            'home_field_advantage': 0 if is_neutral else 2.5,\n",
    "            'is_playoff': 1 if is_playoff else 0,\n",
    "            'is_neutral': 1 if is_neutral else 0,\n",
    "            'week': week,\n",
    "            'season': season,\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def build_dataset(self, pbp_data, weekly_data, schedule_data, save_csv=True, data_folder='nfl_data'):\n",
    "        \"\"\"Build complete dataset from NFL data and optionally save as CSV\"\"\"\n",
    "        \n",
    "        print(\"Building dataset from collected data...\")\n",
    "        \n",
    "        game_records = []\n",
    "        \n",
    "        # Process each scheduled game\n",
    "        for _, game in schedule_data.iterrows():\n",
    "            season = game['season']\n",
    "            week = game['week']\n",
    "            home_team = game['home_team']\n",
    "            away_team = game['away_team']\n",
    "            \n",
    "            # Skip if missing essential data\n",
    "            if pd.isna(home_team) or pd.isna(away_team):\n",
    "                continue\n",
    "            \n",
    "            # Get team features up to this point in season\n",
    "            team_features = self.create_team_features(weekly_data, season, week)\n",
    "            \n",
    "            if not team_features:\n",
    "                continue\n",
    "            \n",
    "            # Create game features\n",
    "            game_features = self.create_game_features(\n",
    "                home_team, away_team, team_features, \n",
    "                season, week,\n",
    "                is_playoff=game.get('game_type', '') == 'REG',\n",
    "                is_neutral=False  # Simplified for now\n",
    "            )\n",
    "            \n",
    "            if game_features is None:\n",
    "                continue\n",
    "            \n",
    "            # Determine result (home team win = 1, loss = 0)\n",
    "            home_score = game.get('home_score', 0)\n",
    "            away_score = game.get('away_score', 0)\n",
    "            \n",
    "            # Skip games without scores (future games)\n",
    "            if pd.isna(home_score) or pd.isna(away_score):\n",
    "                continue\n",
    "            \n",
    "            game_features['home_win'] = 1 if home_score > away_score else 0\n",
    "            game_features['home_score'] = home_score\n",
    "            game_features['away_score'] = away_score\n",
    "            game_features['game_id'] = f\"{season}_{week}_{home_team}_{away_team}\"\n",
    "            \n",
    "            game_records.append(game_features)\n",
    "        \n",
    "        df = pd.DataFrame(game_records)\n",
    "        print(f\"Created dataset with {len(df)} games\")\n",
    "        \n",
    "        # Save the processed dataset\n",
    "        if save_csv and not df.empty:\n",
    "            if not os.path.exists(data_folder):\n",
    "                os.makedirs(data_folder)\n",
    "            \n",
    "            processed_file = os.path.join(data_folder, 'processed_game_features.csv')\n",
    "            df.to_csv(processed_file, index=False)\n",
    "            print(f\"✓ Saved processed game features: {processed_file} ({len(df):,} rows)\")\n",
    "            \n",
    "            # Show feature information\n",
    "            print(f\"\\nPROCESSED FEATURES ({len(df.columns)} columns):\")\n",
    "            print(\"=\"*50)\n",
    "            for col in df.columns:\n",
    "                print(f\"  - {col}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def select_features(self, df, n_features=13):\n",
    "        \"\"\"Select best features using RFE\"\"\"\n",
    "        \n",
    "        # Prepare data\n",
    "        feature_cols = [col for col in df.columns \n",
    "                       if col not in ['home_win', 'home_score', 'away_score', 'game_id']]\n",
    "        \n",
    "        X = df[feature_cols]\n",
    "        y = df['home_win']\n",
    "        \n",
    "        # Remove any columns with all NaN or constant values\n",
    "        X = X.loc[:, X.var() > 0]\n",
    "        X = X.fillna(X.mean())\n",
    "        \n",
    "        print(f\"Starting feature selection with {len(X.columns)} features...\")\n",
    "        \n",
    "        # Use RFE with different numbers of features\n",
    "        models = {}\n",
    "        results = []\n",
    "        \n",
    "        for i in range(2, min(n_features + 1, len(X.columns) + 1)):\n",
    "            rfe = RFE(estimator=LDA(), n_features_to_select=i)\n",
    "            model = DecisionTreeClassifier(random_state=42)\n",
    "            pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "            \n",
    "            cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "            scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "            \n",
    "            results.append(scores)\n",
    "            models[str(i)] = pipeline\n",
    "            \n",
    "            print(f'{i} features: {scores.mean():.3f} (+/- {scores.std():.3f})')\n",
    "        \n",
    "        # Find best number of features\n",
    "        best_idx = np.argmax([np.mean(result) for result in results])\n",
    "        best_n_features = best_idx + 2\n",
    "        \n",
    "        print(f\"Best number of features: {best_n_features}\")\n",
    "        \n",
    "        # Get the best feature set\n",
    "        rfe = RFE(estimator=LDA(), n_features_to_select=best_n_features)\n",
    "        rfe.fit(X, y)\n",
    "        \n",
    "        selected_features = X.columns[rfe.support_].tolist()\n",
    "        self.best_features = selected_features\n",
    "        \n",
    "        print(\"Selected features:\")\n",
    "        for feature in selected_features:\n",
    "            print(f\"  - {feature}\")\n",
    "        \n",
    "        return selected_features\n",
    "    \n",
    "    def train_models(self, df):\n",
    "        \"\"\"Train and compare multiple models\"\"\"\n",
    "        \n",
    "        if not self.best_features:\n",
    "            self.select_features(df)\n",
    "        \n",
    "        # Prepare data\n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['home_win']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Define models to test\n",
    "        models_to_test = {\n",
    "            'Logistic Regression': LogisticRegression(random_state=42),\n",
    "            'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "            'Random Forest': RandomForestClassifier(random_state=42)\n",
    "        }\n",
    "        \n",
    "        if HAS_XGB:\n",
    "            models_to_test['XGBoost'] = xgb.XGBClassifier(random_state=42, verbosity=0)\n",
    "        \n",
    "        # Train and evaluate models\n",
    "        model_results = {}\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "        \n",
    "        print(\"\\nTraining and evaluating models...\")\n",
    "        \n",
    "        for name, model in models_to_test.items():\n",
    "            # Use scaled data for logistic regression, raw for tree-based\n",
    "            X_use = X_train_scaled if 'Logistic' in name else X_train\n",
    "            scores = cross_val_score(model, X_use, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "            \n",
    "            model_results[name] = {\n",
    "                'mean_score': scores.mean(),\n",
    "                'std_score': scores.std(),\n",
    "                'scores': scores\n",
    "            }\n",
    "            \n",
    "            print(f\"{name}: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "        \n",
    "        self.models = models_to_test\n",
    "        return model_results\n",
    "    \n",
    "    def tune_best_model(self, df, model_name='Random Forest'):\n",
    "        \"\"\"Tune hyperparameters for the best performing model\"\"\"\n",
    "        \n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['home_win']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        if model_name == 'Random Forest':\n",
    "            param_grid = {\n",
    "                'n_estimators': [200, 300, 400, 500],\n",
    "                'max_depth': [8, 9, 10, 11, 12],\n",
    "                'min_samples_leaf': [2, 5],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "            model = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        elif model_name == 'Logistic Regression':\n",
    "            param_grid = {\n",
    "                'C': [0.01, 0.1, 1, 10, 100],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'solver': ['liblinear']\n",
    "            }\n",
    "            model = LogisticRegression(random_state=42)\n",
    "            X_train = self.scaler.fit_transform(X_train)\n",
    "            X_test = self.scaler.transform(X_test)\n",
    "        \n",
    "        elif model_name == 'XGBoost' and HAS_XGB:\n",
    "            param_grid = {\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'reg_alpha': [0, 1],\n",
    "            'reg_lambda': [1, 5]\n",
    "            }\n",
    "            model = xgb.XGBClassifier(random_state=42, verbosity=0)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Tuning not implemented for {model_name}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\nTuning {model_name}...\")\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, \n",
    "            cv=5, scoring='accuracy', \n",
    "            n_jobs=-1, verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")\n",
    "        \n",
    "        # Test on holdout set\n",
    "        test_score = grid_search.score(X_test, y_test)\n",
    "        print(f\"Test set accuracy: {test_score:.3f}\")\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def create_ensemble_model(self, df):\n",
    "        \"\"\"Create ensemble model combining multiple algorithms\"\"\"\n",
    "        \n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['home_win']\n",
    "        \n",
    "        # Individual models\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
    "        lr = LogisticRegression(C=1, random_state=42)\n",
    "        \n",
    "        estimators = [('rf', rf), ('lr', lr)]\n",
    "        \n",
    "        if HAS_XGB:\n",
    "            xgb_model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=200, \n",
    "                                        random_state=42, verbosity=0)\n",
    "            estimators.append(('xgb', xgb_model))\n",
    "        \n",
    "        # Voting classifier\n",
    "        voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "        \n",
    "        # Calibrated classifier for better probability estimates\n",
    "        self.final_model = CCV(voting_clf, method='isotonic', cv=3)\n",
    "        \n",
    "        print(\"Training ensemble model...\")\n",
    "        self.final_model.fit(X, y)\n",
    "        \n",
    "        return self.final_model\n",
    "    \n",
    "    def predict_games(self, games_df, confidence_threshold=0.6):\n",
    "        \"\"\"Make predictions on new games\"\"\"\n",
    "        \n",
    "        if self.final_model is None:\n",
    "            raise ValueError(\"Model not trained yet. Call create_ensemble_model() first.\")\n",
    "        \n",
    "        X = games_df[self.best_features].fillna(games_df[self.best_features].mean())\n",
    "        \n",
    "        # Get probability predictions\n",
    "        probabilities = self.final_model.predict_proba(X)[:, 1]\n",
    "        predictions = self.final_model.predict(X)\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = games_df.copy()\n",
    "        results['home_win_prob'] = probabilities\n",
    "        results['predicted_home_win'] = predictions\n",
    "        \n",
    "        # High-confidence bets\n",
    "        results['high_confidence_bet'] = (\n",
    "            (probabilities >= confidence_threshold) | \n",
    "            (probabilities <= (1 - confidence_threshold))\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Initialize predictor\n",
    "    predictor = NFLGamePredictor()\n",
    "    \n",
    "    # Check if nfl_data_py is available\n",
    "    if not HAS_NFL_DATA:\n",
    "        print(\"Please install nfl_data_py to use this predictor:\")\n",
    "        print(\"pip install nfl_data_py\")\n",
    "        exit()\n",
    "    \n",
    "    try:\n",
    "        # Collect data (this may take a few minutes)\n",
    "        print(\"This may take a few minutes to download NFL data...\")\n",
    "        pbp_data, weekly_data, schedule_data, team_dict = predictor.collect_data(2015, 2025, save_csv=True)\n",
    "        \n",
    "        # Build dataset\n",
    "        df = predictor.build_dataset(pbp_data, weekly_data, schedule_data, save_csv=True)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"No data collected. Check your internet connection and try again.\")\n",
    "            exit()\n",
    "        \n",
    "        # Feature selection\n",
    "        predictor.select_features(df, n_features=13)\n",
    "        \n",
    "        # Train models\n",
    "        model_results = predictor.train_models(df)\n",
    "        \n",
    "        # Create ensemble\n",
    "        final_model = predictor.create_ensemble_model(df)\n",
    "        \n",
    "        # Example prediction on test set\n",
    "        train_data = df[df['season'] < 2023]\n",
    "        test_data = df[df['season'] == 2023]\n",
    "        \n",
    "        if not test_data.empty:\n",
    "            predictor.final_model.fit(\n",
    "                train_data[predictor.best_features].fillna(train_data[predictor.best_features].mean()), \n",
    "                train_data['home_win']\n",
    "            )\n",
    "            \n",
    "            predictions = predictor.predict_games(test_data)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (predictions['predicted_home_win'] == predictions['home_win']).mean()\n",
    "            print(f\"\\n2023 season prediction accuracy: {accuracy:.3f}\")\n",
    "            \n",
    "            # High confidence bets\n",
    "            high_conf = predictions[predictions['high_confidence_bet']]\n",
    "            if not high_conf.empty:\n",
    "                conf_accuracy = (high_conf['predicted_home_win'] == high_conf['home_win']).mean()\n",
    "                print(f\"High confidence bet accuracy: {conf_accuracy:.3f} ({len(high_conf)} games)\")\n",
    "        \n",
    "        print(\"\\nPredictor trained successfully!\")\n",
    "        print(\"You can now use predictor.predict_games() on new data.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure you have a stable internet connection for data download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277fd8d",
   "metadata": {},
   "source": [
    "## Step 3: Save the Model (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "339c9be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "\n",
    "joblib.dump(predictor.final_model, 'final_model.joblib')\n",
    "\n",
    "# To load later:\n",
    "# predictor.final_model = joblib.load('nfl_data/final_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5edd4",
   "metadata": {},
   "source": [
    "## Step 3: NFL Spread Prediction Model\n",
    "\n",
    "This enhanced version predicts **point spreads** instead of just winners, providing much more detailed and useful information:\n",
    "\n",
    "**Key Differences:**\n",
    "- **Winner Model**: \"Chiefs beat Bills (72% confidence)\"\n",
    "- **Spread Model**: \"Chiefs -6.5 points\" (tells you HOW MUCH they'll win by)\n",
    "\n",
    "**Benefits:**\n",
    "- More accurate assessment of game competitiveness\n",
    "- Better for betting analysis (spread, over/under, props)\n",
    "- Distinguishes between close games and blowouts\n",
    "- Aligns with how Vegas and analysts actually think about games\n",
    "\n",
    "**Output Format:**\n",
    "- Positive spread = Home team favored (e.g., \"Chiefs -7\" means KC favored by 7)\n",
    "- Negative spread = Away team favored (e.g., \"Bills +3\" means BUF getting 3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "357daa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFL SPREAD PREDICTION MODEL READY!\n",
      "\n",
      "This model predicts:\n",
      "  - Point spreads (e.g., Chiefs -7.5)\n",
      "  - How much teams will win/lose by\n",
      "  - More detailed game analysis\n",
      "\n",
      "Next: Train the spread model using existing data!\n"
     ]
    }
   ],
   "source": [
    "# NFL SPREAD PREDICTION MODEL\n",
    "# Enhanced version that predicts point spreads instead of just winners\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "class NFLSpreadPredictor:\n",
    "    def __init__(self):\n",
    "        self.spread_model = None\n",
    "        self.best_features = []\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def prepare_spread_data(self, df):\n",
    "        \"\"\"Convert winner prediction data to spread prediction data\"\"\"\n",
    "        \n",
    "        # Create point differential (home_score - away_score)\n",
    "        df['point_spread'] = df['home_score'] - df['away_score']\n",
    "        \n",
    "        print(f\"Spread Data Summary:\")\n",
    "        print(f\"  Games: {len(df)}\")\n",
    "        print(f\"  Average spread: {df['point_spread'].mean():.1f} points\")\n",
    "        print(f\"  Spread range: {df['point_spread'].min():.0f} to {df['point_spread'].max():.0f}\")\n",
    "        print(f\"  Home team wins: {(df['point_spread'] > 0).sum()} ({(df['point_spread'] > 0).mean():.1%})\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def train_spread_model(self, df, use_existing_features=True):\n",
    "        \"\"\"Train regression model to predict point spreads\"\"\"\n",
    "        \n",
    "        # Prepare spread data\n",
    "        df = self.prepare_spread_data(df)\n",
    "        \n",
    "        # Use existing features or select new ones for regression\n",
    "        if use_existing_features and hasattr(predictor, 'best_features') and predictor.best_features:\n",
    "            self.best_features = predictor.best_features\n",
    "            print(f\"Using existing features: {len(self.best_features)} features\")\n",
    "        else:\n",
    "            # Select features for regression\n",
    "            feature_cols = [col for col in df.columns \n",
    "                           if col not in ['home_win', 'home_score', 'away_score', 'game_id', 'point_spread']]\n",
    "            self.best_features = feature_cols[:15]  # Use top 15 features\n",
    "            print(f\"Selected {len(self.best_features)} features for spread prediction\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['point_spread']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Test multiple regression models\n",
    "        models = {\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42),\n",
    "            'Linear Regression': LinearRegression(),\n",
    "        }\n",
    "        \n",
    "        if HAS_XGB:\n",
    "            models['XGBoost'] = xgb.XGBRegressor(n_estimators=200, max_depth=6, random_state=42, verbosity=0)\n",
    "        \n",
    "        print(\"\\nTraining spread prediction models...\")\n",
    "        best_model = None\n",
    "        best_mae = float('inf')\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            # Use scaled data for linear regression, raw for tree-based\n",
    "            X_use_train = X_train_scaled if 'Linear' in name else X_train\n",
    "            X_use_test = X_test_scaled if 'Linear' in name else X_test\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_use_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_use_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            print(f\"{name}:\")\n",
    "            print(f\"  MAE: {mae:.2f} points\")\n",
    "            print(f\"  RMSE: {rmse:.2f} points\")\n",
    "            \n",
    "            # Select best model based on MAE\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_model = model\n",
    "                self.spread_model = model\n",
    "                print(f\"  *** NEW BEST MODEL ***\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"Best model MAE: {best_mae:.2f} points\")\n",
    "        return self.spread_model\n",
    "    \n",
    "    def predict_spreads(self, games_df):\n",
    "        \"\"\"Predict point spreads for new games\"\"\"\n",
    "        \n",
    "        if self.spread_model is None:\n",
    "            raise ValueError(\"Spread model not trained yet!\")\n",
    "        \n",
    "        X = games_df[self.best_features].fillna(games_df[self.best_features].mean())\n",
    "        \n",
    "        # Use appropriate scaling based on model type\n",
    "        if 'Linear' in str(type(self.spread_model)):\n",
    "            X = self.scaler.transform(X)\n",
    "        \n",
    "        # Get spread predictions\n",
    "        predicted_spreads = self.spread_model.predict(X)\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = games_df.copy()\n",
    "        results['predicted_spread'] = predicted_spreads\n",
    "        \n",
    "        # Determine winner based on spread\n",
    "        results['predicted_winner_spread'] = np.where(\n",
    "            predicted_spreads > 0, \n",
    "            results.get('home_team', 'HOME'),  # Home team wins if spread > 0\n",
    "            results.get('away_team', 'AWAY')   # Away team wins if spread < 0\n",
    "        )\n",
    "        \n",
    "        # Calculate confidence based on magnitude of spread\n",
    "        results['spread_confidence'] = np.abs(predicted_spreads) / 21.0  # Scale by typical max spread\n",
    "        results['spread_confidence'] = np.clip(results['spread_confidence'], 0.5, 0.95)  # 50-95% range\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize spread predictor\n",
    "spread_predictor = NFLSpreadPredictor()\n",
    "\n",
    "print(\"NFL SPREAD PREDICTION MODEL READY!\")\n",
    "print(\"\\nThis model predicts:\")\n",
    "print(\"  - Point spreads (e.g., Chiefs -7.5)\")\n",
    "print(\"  - How much teams will win/lose by\")\n",
    "print(\"  - More detailed game analysis\")\n",
    "print(\"\\nNext: Train the spread model using existing data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bff0634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING NFL SPREAD PREDICTION MODEL\n",
      "==================================================\n",
      "Training spread model on historical data...\n",
      "Spread Data Summary:\n",
      "  Games: 2465\n",
      "  Average spread: 2.0 points\n",
      "  Spread range: -45 to 50\n",
      "  Home team wins: 1356 (55.0%)\n",
      "Using existing features: 10 features\n",
      "\n",
      "Training spread prediction models...\n",
      "Random Forest:\n",
      "  MAE: 10.86 points\n",
      "  RMSE: 14.30 points\n",
      "  *** NEW BEST MODEL ***\n",
      "\n",
      "Linear Regression:\n",
      "  MAE: 10.97 points\n",
      "  RMSE: 14.41 points\n",
      "\n",
      "XGBoost:\n",
      "  MAE: 12.22 points\n",
      "  RMSE: 15.64 points\n",
      "\n",
      "Best model MAE: 10.86 points\n",
      "✓ Spread model trained successfully!\n",
      "\n",
      "Model can now predict:\n",
      "  - Point spreads (e.g., 'Chiefs -7.5')\n",
      "  - Victory margins\n",
      "  - Game competitiveness\n",
      "\n",
      "Testing on recent games...\n",
      "Sample predictions:\n",
      "  PHI -7.0 vs WAS (actual: +32)\n",
      "  BUF -2.9 vs KC (actual: +3)\n",
      "  PHI -10.4 vs KC (actual: +18)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE SPREAD MODEL\n",
    "print(\"TRAINING NFL SPREAD PREDICTION MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if we have the original data\n",
    "if 'df' in locals() or 'df' in globals():\n",
    "    try:\n",
    "        # Train spread model using existing dataset\n",
    "        print(\"Training spread model on historical data...\")\n",
    "        \n",
    "        spread_model = spread_predictor.train_spread_model(df, use_existing_features=True)\n",
    "        \n",
    "        if spread_model is not None:\n",
    "            print(\"✓ Spread model trained successfully!\")\n",
    "            print(\"\\nModel can now predict:\")\n",
    "            print(\"  - Point spreads (e.g., 'Chiefs -7.5')\")\n",
    "            print(\"  - Victory margins\")\n",
    "            print(\"  - Game competitiveness\")\n",
    "            \n",
    "            # Test on a few sample games\n",
    "            print(f\"\\nTesting on recent games...\")\n",
    "            test_games = df.tail(3)\n",
    "            if not test_games.empty:\n",
    "                spread_results = spread_predictor.predict_spreads(test_games)\n",
    "                \n",
    "                print(\"Sample predictions:\")\n",
    "                for _, game in spread_results.iterrows():\n",
    "                    home_team = game.get('game_id', 'Unknown').split('_')[-2] if 'game_id' in game else 'HOME'\n",
    "                    away_team = game.get('game_id', 'Unknown').split('_')[-1] if 'game_id' in game else 'AWAY'\n",
    "                    spread = game['predicted_spread']\n",
    "                    actual_spread = game.get('point_spread', 0)\n",
    "                    \n",
    "                    if spread > 0:\n",
    "                        print(f\"  {home_team} -{abs(spread):.1f} vs {away_team} (actual: {actual_spread:+.0f})\")\n",
    "                    else:\n",
    "                        print(f\"  {away_team} -{abs(spread):.1f} vs {home_team} (actual: {actual_spread:+.0f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training spread model: {e}\")\n",
    "        print(\"Make sure the original model data is available.\")\n",
    "        \n",
    "else:\n",
    "    print(\"ERROR: No training data found!\")\n",
    "    print(\"Please run Step 2 first to collect and prepare the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f84d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENHANCED SPREAD PREDICTION FUNCTION READY!\n",
      "\n",
      "This function provides:\n",
      "  - Winner predictions with confidence\n",
      "  - Point spread predictions\n",
      "  - Game competitiveness analysis\n",
      "  - Betting-focused insights\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED SPREAD PREDICTION FUNCTION\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def predict_multiple_games_with_spreads(predictor, spread_predictor, games_text, season=2025, week=6, show_details=True):\n",
    "    \"\"\"\n",
    "    Predict multiple games with BOTH winner probabilities AND point spreads\n",
    "    \n",
    "    Args:\n",
    "        predictor: Trained NFLGamePredictor instance (for winner predictions)\n",
    "        spread_predictor: Trained NFLSpreadPredictor instance (for spread predictions)\n",
    "        games_text: Formatted text with games\n",
    "        season: Season year\n",
    "        week: Week number\n",
    "        show_details: Whether to show detailed output\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with both winner and spread predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    if predictor.final_model is None:\n",
    "        return None\n",
    "        \n",
    "    if spread_predictor.spread_model is None:\n",
    "        return None\n",
    "    \n",
    "    # Use existing team mapping from original function\n",
    "    team_mapping = {\n",
    "        'TB Buccaneers': 'TB', 'Tampa Bay Buccaneers': 'TB', 'TB': 'TB',\n",
    "        'ATL Falcons': 'ATL', 'Atlanta Falcons': 'ATL', 'ATL': 'ATL',\n",
    "        'CIN Bengals': 'CIN', 'Cincinnati Bengals': 'CIN', 'CIN': 'CIN',\n",
    "        'CLE Browns': 'CLE', 'Cleveland Browns': 'CLE', 'CLE': 'CLE',\n",
    "        'MIA Dolphins': 'MIA', 'Miami Dolphins': 'MIA', 'MIA': 'MIA',\n",
    "        'IND Colts': 'IND', 'Indianapolis Colts': 'IND', 'IND': 'IND',\n",
    "        'CAR Panthers': 'CAR', 'Carolina Panthers': 'CAR', 'CAR': 'CAR',\n",
    "        'JAX Jaguars': 'JAX', 'Jacksonville Jaguars': 'JAX', 'JAX': 'JAX',\n",
    "        'LV Raiders': 'LV', 'Las Vegas Raiders': 'LV', 'LV': 'LV',\n",
    "        'NE Patriots': 'NE', 'New England Patriots': 'NE', 'NE': 'NE',\n",
    "        'ARI Cardinals': 'ARI', 'Arizona Cardinals': 'ARI', 'ARI': 'ARI',\n",
    "        'NO Saints': 'NO', 'New Orleans Saints': 'NO', 'NO': 'NO',\n",
    "        'PIT Steelers': 'PIT', 'Pittsburgh Steelers': 'PIT', 'PIT': 'PIT',\n",
    "        'NYJ Jets': 'NYJ', 'New York Jets': 'NYJ', 'NYJ': 'NYJ',\n",
    "        'NYG Giants': 'NYG', 'New York Giants': 'NYG', 'NYG': 'NYG',\n",
    "        'WAS Commanders': 'WAS', 'Washington Commanders': 'WAS', 'WAS': 'WAS',\n",
    "        'TEN Titans': 'TEN', 'Tennessee Titans': 'TEN', 'TEN': 'TEN',\n",
    "        'DEN Broncos': 'DEN', 'Denver Broncos': 'DEN', 'DEN': 'DEN',\n",
    "        'SF 49ers': 'SF', 'San Francisco 49ers': 'SF', 'SF': 'SF',\n",
    "        'SEA Seahawks': 'SEA', 'Seattle Seahawks': 'SEA', 'SEA': 'SEA',\n",
    "        'DET Lions': 'DET', 'Detroit Lions': 'DET', 'DET': 'DET',\n",
    "        'GB Packers': 'GB', 'Green Bay Packers': 'GB', 'GB': 'GB',\n",
    "        'HOU Texans': 'HOU', 'Houston Texans': 'HOU', 'HOU': 'HOU',\n",
    "        'LA Rams': 'LA', 'Los Angeles Rams': 'LA', 'LA': 'LA',\n",
    "        'LAR Rams': 'LA', 'Los Angeles Rams': 'LA', 'LAR': 'LA',\n",
    "        'BAL Ravens': 'BAL', 'Baltimore Ravens': 'BAL', 'BAL': 'BAL',\n",
    "        'BUF Bills': 'BUF', 'Buffalo Bills': 'BUF', 'BUF': 'BUF',\n",
    "        'KC Chiefs': 'KC', 'Kansas City Chiefs': 'KC', 'KC': 'KC',\n",
    "        'PHI Eagles': 'PHI', 'Philadelphia Eagles': 'PHI', 'PHI': 'PHI',\n",
    "        'DAL Cowboys': 'DAL', 'Dallas Cowboys': 'DAL', 'DAL': 'DAL',\n",
    "        'MIN Vikings': 'MIN', 'Minnesota Vikings': 'MIN', 'MIN': 'MIN',\n",
    "        'CHI Bears': 'CHI', 'Chicago Bears': 'CHI', 'CHI': 'CHI',\n",
    "        'LAC Chargers': 'LAC', 'Los Angeles Chargers': 'LAC', 'LAC': 'LAC'\n",
    "    }\n",
    "    \n",
    "    # Parse games\n",
    "    game_pattern = r'\\(Away\\)\\s+(.*?)\\s+vs\\.\\s+\\(Home\\)\\s+(.*)'\n",
    "    matches = re.findall(game_pattern, games_text, re.IGNORECASE)\n",
    "    \n",
    "    if not matches:\n",
    "        return None\n",
    "    \n",
    "    # Get team features\n",
    "    try:\n",
    "        team_features = predictor.create_team_features(weekly_data, 2025, week)\n",
    "        if not team_features:\n",
    "            team_features = predictor.create_team_features(weekly_data, 2024, 19)\n",
    "            data_source = \"2024 season-end\"\n",
    "        else:\n",
    "            data_source = f\"2025 Week {week-1}\"\n",
    "            \n",
    "        if not team_features:\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    all_predictions = []\n",
    "    successful_predictions = 0\n",
    "    \n",
    "    for i, (away_full, home_full) in enumerate(matches, 1):\n",
    "        away_full = away_full.strip()\n",
    "        home_full = home_full.strip()\n",
    "        \n",
    "        # Map to abbreviations\n",
    "        away_team = team_mapping.get(away_full, away_full.split()[-1] if away_full.split() else away_full)\n",
    "        home_team = team_mapping.get(home_full, home_full.split()[-1] if home_full.split() else home_full)\n",
    "        \n",
    "        away_team = away_team.strip().upper()\n",
    "        home_team = home_team.strip().upper()\n",
    "        \n",
    "        try:\n",
    "            # Check if teams exist\n",
    "            if away_team not in team_features or home_team not in team_features:\n",
    "                continue\n",
    "            \n",
    "            # Create game features\n",
    "            game_features = predictor.create_game_features(\n",
    "                home_team, away_team, team_features,\n",
    "                season, week, is_playoff=False, is_neutral=False\n",
    "            )\n",
    "            \n",
    "            if game_features is None:\n",
    "                continue\n",
    "            \n",
    "            game_df = pd.DataFrame([game_features])\n",
    "            \n",
    "            # Get BOTH winner and spread predictions\n",
    "            winner_result = predictor.predict_games(game_df)\n",
    "            spread_result = spread_predictor.predict_spreads(game_df)\n",
    "            \n",
    "            # Extract results\n",
    "            home_win_prob = winner_result['home_win_prob'].iloc[0]\n",
    "            predicted_home_win = winner_result['predicted_home_win'].iloc[0]\n",
    "            predicted_spread = spread_result['predicted_spread'].iloc[0]\n",
    "            \n",
    "            # CRITICAL: Ensure spread and winner are consistent\n",
    "            # The team with the negative spread MUST be the predicted winner\n",
    "            # Calculate confidence based on spread: Win Probability ≈ 50% + (spread × 2.5%)\n",
    "            spread_magnitude = abs(predicted_spread)\n",
    "            spread_based_confidence = 0.50 + (spread_magnitude * 0.025)\n",
    "            spread_based_confidence = min(spread_based_confidence, 0.95)  \n",
    "            \n",
    "            if predicted_spread > 0:\n",
    "                # Home team favored (positive spread means home team wins)\n",
    "                spread_display = f\"{home_team} -{abs(predicted_spread):.1f}\"\n",
    "                favored_team = home_team\n",
    "                winner = home_team  # Winner must match the favored team\n",
    "                confidence = spread_based_confidence\n",
    "            else:\n",
    "                # Away team favored (negative spread means away team wins)\n",
    "                spread_display = f\"{away_team} -{abs(predicted_spread):.1f}\"\n",
    "                favored_team = away_team\n",
    "                winner = away_team  # Winner must match the favored team\n",
    "                confidence = spread_based_confidence\n",
    "            \n",
    "            # Store comprehensive prediction\n",
    "            prediction_data = {\n",
    "                'game_num': i,\n",
    "                'away_team': away_team,\n",
    "                'home_team': home_team,\n",
    "                'matchup': f\"{away_team} @ {home_team}\",\n",
    "                'predicted_winner': winner,\n",
    "                'confidence': confidence,\n",
    "                'home_win_prob': home_win_prob,\n",
    "                'away_win_prob': 1 - home_win_prob,\n",
    "                'predicted_spread': predicted_spread,\n",
    "                'spread_display': spread_display,\n",
    "                'favored_team': favored_team,\n",
    "                'spread_magnitude': abs(predicted_spread)\n",
    "            }\n",
    "            \n",
    "            all_predictions.append(prediction_data)\n",
    "            successful_predictions += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if not all_predictions:\n",
    "        return None\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    predictions_df = pd.DataFrame(all_predictions)\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "print(\"ENHANCED SPREAD PREDICTION FUNCTION READY!\")\n",
    "print(\"\\nThis function provides:\")\n",
    "print(\"  - Winner predictions with confidence\")\n",
    "print(\"  - Point spread predictions\")\n",
    "print(\"  - Game competitiveness analysis\")\n",
    "print(\"  - Betting-focused insights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e44ab5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTING NFL WEEK 6 SPREAD PREDICTIONS\n",
      "============================================================\n",
      "Both models are trained and ready!\n",
      "Generating comprehensive predictions with spreads...\n",
      "\n",
      "\n",
      "\n",
      "WEEK 7 PREDICTIONS\n",
      "======================================================================\n",
      "MATCHUP              SPREAD          WINNER       CONFIDENCE  \n",
      "----------------------------------------------------------------------\n",
      "PIT @ CIN            CIN -10.0       Bengals      74.9%\n",
      "LA @ JAX             LA -3.9         Rams         59.8%\n",
      "PHI @ MIN            PHI -2.8        Eagles       57.0%\n",
      "NE @ TEN             TEN -4.8        Titans       62.1%\n",
      "CAR @ NYJ            NYJ -6.3        Jets         65.7%\n",
      "MIA @ CLE            MIA -2.2        Dolphins     55.5%\n",
      "NO @ CHI             CHI -6.1        Bears        65.3%\n",
      "LV @ KC              KC -7.9         Chiefs       69.8%\n",
      "IND @ LAC            LAC -1.8        Chargers     54.6%\n",
      "NYG @ DEN            DEN -7.2        Broncos      68.0%\n",
      "GB @ ARI             GB -1.5         Packers      53.7%\n",
      "WAS @ DAL            WAS -2.9        Commanders   57.1%\n",
      "ATL @ SF             ATL -0.3        Falcons      50.7%\n",
      "TB @ DET             DET -1.4        Lions        53.5%\n",
      "HOU @ SEA            SEA -5.5        Seahawks     63.8%\n",
      "----------------------------------------------------------------------\n",
      "Total Games: 15 | Avg Spread: 4.3 pts\n",
      "\n",
      "GAME ANALYSIS:\n",
      "  Close games (≤3.5 pts): 7\n",
      "  Potential blowouts (≥10 pts): 0\n",
      "  Home teams favored: 9\n",
      "  Away teams favored: 6\n",
      "\n",
      "Results saved to 'week7_spread_results' variable\n",
      "\n",
      "\n",
      "WEEK 7 PREDICTIONS\n",
      "======================================================================\n",
      "MATCHUP              SPREAD          WINNER       CONFIDENCE  \n",
      "----------------------------------------------------------------------\n",
      "PIT @ CIN            CIN -10.0       Bengals      74.9%\n",
      "LA @ JAX             LA -3.9         Rams         59.8%\n",
      "PHI @ MIN            PHI -2.8        Eagles       57.0%\n",
      "NE @ TEN             TEN -4.8        Titans       62.1%\n",
      "CAR @ NYJ            NYJ -6.3        Jets         65.7%\n",
      "MIA @ CLE            MIA -2.2        Dolphins     55.5%\n",
      "NO @ CHI             CHI -6.1        Bears        65.3%\n",
      "LV @ KC              KC -7.9         Chiefs       69.8%\n",
      "IND @ LAC            LAC -1.8        Chargers     54.6%\n",
      "NYG @ DEN            DEN -7.2        Broncos      68.0%\n",
      "GB @ ARI             GB -1.5         Packers      53.7%\n",
      "WAS @ DAL            WAS -2.9        Commanders   57.1%\n",
      "ATL @ SF             ATL -0.3        Falcons      50.7%\n",
      "TB @ DET             DET -1.4        Lions        53.5%\n",
      "HOU @ SEA            SEA -5.5        Seahawks     63.8%\n",
      "----------------------------------------------------------------------\n",
      "Total Games: 15 | Avg Spread: 4.3 pts\n",
      "\n",
      "GAME ANALYSIS:\n",
      "  Close games (≤3.5 pts): 7\n",
      "  Potential blowouts (≥10 pts): 0\n",
      "  Home teams favored: 9\n",
      "  Away teams favored: 6\n",
      "\n",
      "Results saved to 'week7_spread_results' variable\n"
     ]
    }
   ],
   "source": [
    "# EXECUTE WEEK 6 SPREAD PREDICTIONS\n",
    "print(\"EXECUTING NFL WEEK 6 SPREAD PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "# Week 6 Complete Schedule (October 2025)\n",
    "week7_games = \"\"\"\n",
    "(Away) Pittsburgh Steelers vs. (Home) Cincinnati Bengals\n",
    "(Away) Los Angeles Rams vs. (Home) Jacksonville Jaguars\n",
    "(Away) Philadelphia Eagles vs. (Home) Minnesota Vikings\n",
    "(Away) New England Patriots vs. (Home) Tennessee Titans\n",
    "(Away) Carolina Panthers vs. (Home) New York Jets\n",
    "(Away) Miami Dolphins vs. (Home) Cleveland Browns\n",
    "(Away) New Orleans Saints vs. (Home) Chicago Bears\n",
    "(Away) Las Vegas Raiders vs. (Home) Kansas City Chiefs\n",
    "(Away) Indianapolis Colts vs. (Home) Los Angeles Chargers\n",
    "(Away) New York Giants vs. (Home) Denver Broncos\n",
    "(Away) Green Bay Packers vs. (Home) Arizona Cardinals\n",
    "(Away) Washington Commanders vs. (Home) Dallas Cowboys\n",
    "(Away) Atlanta Falcons vs. (Home) San Francisco 49ers\n",
    "(Away) Tampa Bay Buccaneers vs. (Home) Detroit Lions\n",
    "(Away) Houston Texans vs. (Home) Seattle Seahawks\n",
    "\"\"\"\n",
    "# Check if both models are trained\n",
    "if ('predictor' in locals() and hasattr(predictor, 'final_model') and predictor.final_model is not None and\n",
    "    'spread_predictor' in locals() and hasattr(spread_predictor, 'spread_model') and spread_predictor.spread_model is not None):\n",
    "    \n",
    "    print(\"Both models are trained and ready!\")\n",
    "    print(\"Generating comprehensive predictions with spreads...\")\n",
    "    print()\n",
    "\n",
    "    # Run enhanced predictions with spreads\n",
    "    week7_spread_results = predict_multiple_games_with_spreads(\n",
    "        predictor, spread_predictor, week7_games, \n",
    "        season=2025, week=7, show_details=False\n",
    "    )\n",
    "\n",
    "    if week7_spread_results is not None:\n",
    "        print(f\"\\n\\nWEEK 7 PREDICTIONS\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'MATCHUP':<20} {'SPREAD':<15} {'WINNER':<12} {'CONFIDENCE':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Week 7 game schedule\n",
    "        game_schedule = {\n",
    "            'PIT @ CIN': ('Thursday', '8:15 PM ET'),\n",
    "            'LAR @ JAX': ('Sunday', '9:30 AM ET'),\n",
    "            'PHI @ MIN': ('Sunday', '1:00 PM ET'),\n",
    "            'NE @ TEN': ('Sunday', '1:00 PM ET'),\n",
    "            'CAR @ NYJ': ('Sunday', '1:00 PM ET'),\n",
    "            'MIA @ CLE': ('Sunday', '1:00 PM ET'),\n",
    "            'NO @ CHI': ('Sunday', '1:00 PM ET'),\n",
    "            'LV @ KC': ('Sunday', '1:00 PM ET'),\n",
    "            'IND @ LAC': ('Sunday', '4:05 PM ET'),\n",
    "            'NYG @ DEN': ('Sunday', '4:05 PM ET'),\n",
    "            'GB @ ARI': ('Sunday', '4:25 PM ET'),\n",
    "            'WAS @ DAL': ('Sunday', '4:25 PM ET'),\n",
    "            'ATL @ SF': ('Sunday', '8:20 PM ET'),\n",
    "            'TB @ DET': ('Monday', '7:00 PM ET'),\n",
    "            'HOU @ SEA': ('Monday', '10:00 PM ET')\n",
    "        }\n",
    "        \n",
    "        \n",
    "        time_order = [\n",
    "        'PIT @ CIN', 'LA @ JAX',\n",
    "        'PHI @ MIN', 'NE @ TEN', 'CAR @ NYJ', 'MIA @ CLE', 'NO @ CHI', 'LV @ KC',\n",
    "        'IND @ LAC', 'NYG @ DEN', 'GB @ ARI', 'WAS @ DAL', 'ATL @ SF',\n",
    "        'TB @ DET', 'HOU @ SEA'\n",
    "        ]\n",
    "        \n",
    "        # Team name mapping for display\n",
    "        team_names = {\n",
    "            'WAS': 'Commanders', 'GB': 'Packers', 'NYG': 'Giants', 'DAL': 'Cowboys',\n",
    "            'SEA': 'Seahawks', 'PIT': 'Steelers', 'LA': 'Rams', 'TEN': 'Titans',\n",
    "            'BUF': 'Bills', 'NYJ': 'Jets', 'NE': 'Patriots', 'MIA': 'Dolphins',\n",
    "            'JAX': 'Jaguars', 'CIN': 'Bengals', 'SF': '49ers', 'NO': 'Saints',\n",
    "            'CLE': 'Browns', 'BAL': 'Ravens', 'CHI': 'Bears', 'DET': 'Lions',\n",
    "            'DEN': 'Broncos', 'IND': 'Colts', 'CAR': 'Panthers', 'ARI': 'Cardinals',\n",
    "            'PHI': 'Eagles', 'KC': 'Chiefs', 'ATL': 'Falcons', 'MIN': 'Vikings',\n",
    "            'TB': 'Buccaneers', 'HOU': 'Texans', 'LAC': 'Chargers', 'LV': 'Raiders'\n",
    "        }\n",
    "        \n",
    "        # Display results with spreads\n",
    "        for matchup in time_order:\n",
    "            game_row = week7_spread_results[week7_spread_results['matchup'] == matchup]\n",
    "            if not game_row.empty:\n",
    "                game = game_row.iloc[0]\n",
    "                winner_abbr = game['predicted_winner']\n",
    "                winner_name = team_names.get(winner_abbr, winner_abbr)\n",
    "                spread_display = game['spread_display']\n",
    "                \n",
    "                print(f\"{game['matchup']:<20} {spread_display:<15} {winner_name:<12} {game['confidence']:.1%}\")\n",
    "        \n",
    "        print(\"-\" * 70)\n",
    "        print(f\"Total Games: {len(week7_spread_results)} | Avg Spread: {week7_spread_results['spread_magnitude'].mean():.1f} pts\")\n",
    "        \n",
    "        # Additional insights\n",
    "        close_games = week7_spread_results[week7_spread_results['spread_magnitude'] <= 3.5]\n",
    "        blowouts = week7_spread_results[week7_spread_results['spread_magnitude'] >= 10.0]\n",
    "        print(f\"\\nGAME ANALYSIS:\")\n",
    "        print(f\"  Close games (≤3.5 pts): {len(close_games)}\")\n",
    "        print(f\"  Potential blowouts (≥10 pts): {len(blowouts)}\")\n",
    "        print(f\"  Home teams favored: {(week7_spread_results['predicted_spread'] > 0).sum()}\")\n",
    "        print(f\"  Away teams favored: {(week7_spread_results['predicted_spread'] < 0).sum()}\")\n",
    "\n",
    "        print(f\"\\nResults saved to 'week7_spread_results' variable\")\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Failed to generate spread predictions\")\n",
    "        \n",
    "else:\n",
    "    print(\"ERROR: Models not trained yet!\")\n",
    "    print(\"\\nPlease run:\")\n",
    "    print(\"1. Step 2 to train the winner prediction model\")\n",
    "    print(\"2. Step 8 to train the spread prediction model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
